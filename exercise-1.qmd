---
title: "Estimating survey measurement error"
---

## Introduction

Below, you will find 10 exercises (1.1 -- 1.10) related to the estimation of measurement error in survey questions. You are meant to work through this document gradually, by starting at the top reading, and doing the first exercise in `R`, etc. You may need to install some libraries, which are indicated under "Preliminaries" below. You will also require an internet connection to download the two datasets used in the exercises.

If you have not already done so, it may also be helpful to keep the slides open so you can refer to them as you answer the more knowledge-oriented questions.

Each exercise consists of a question. Often you will need to adapt and run `R` code in order to answer this question. In order to help you along should your experience with `R` be limited, some (hopefully) helpful hints are provided. You can choose to look at these, or not, as you may require. The hints look as shown below. CLick the green bar to reveal the hint.

::: {.callout-tip collapse="true"}
#### I need a hint!
Hints are intended to help you along, especially if you are encountering `R` and/or `lavaan` for the first time. 
:::

Each exercise also provides a solution so you can check your own work. Your learning will be most effective if you try not to look at these right away, but instead attempt the question first. If you really get stuck, or if you are happy with your answer, you could allow yourself to look at the solution, which look as shown below.  Click the orange bar to reveal the solution. 

::: {.callout-caution collapse="true"}
#### Solution
Please try not to look at the solution until you have attempted the question in earnest.
:::

Remember that you are strongly encouraged to consult your instructor and fellow students. Often a very small nudge in the right direction can be enough to get to the right answer!

## Preliminaries

```{r}
library(psych)
library(lavaan)
library(semTools)
library(tidyverse)

options(digits = 4)
```

Load data from ESS
```{r}
load(url("http://daob.nl/files/SURV730/ess7_health.rdata"))
```

## A first look at the European Social Survey data 

In the [European Social Survey round 7](http://www.europeansocialsurvey.org/data/download.html?r=7), data have been collected on 28,221 European's health (among many other topics). I have downloaded and recoded some of these data. You have them available in the R prompt as `ess7_health`. 

This dataset has the following variables in it:

*  dshltgp : DISCUSSED HEALTH, LAST 12 MONTHS: GENERAL PRACTITIONER
*  dosprt : DO SPORTS OR OTHER PHYSICAL ACTIVITY, HOW MANY OF LAST 7 DAYS
*  alcfreq : HOW OFTEN DRINK ALCOHOL
*  etfruit : HOW OFTEN EAT FRUIT, EXCLUDING DRINKING JUICE
*  eatveg : HOW OFTEN EAT VEGETABLES OR SALAD, EXCLUDING POTATOES
*  health : SUBJECTIVE GENERAL HEALTH
*  happy : HOW HAPPY ARE YOU
*  slprl : SLEEP WAS RESTLESS, HOW OFTEN PAST WEEK
*  agea : Age
*  eisced : Education level
*  brncntr : BORN IN COUNTRY
*  smoke : Whether person currently smokes (recode of ESS variable CGTSMKE)
*  BMI : Body mass index (recode of ESS variables HEIGHT and WEIGHT)
*  health_problems : Number of health problems (recode of ESS variables HLTHPRxx)

You may want to *copy-paste this list into a text file for future reference*.

See the link above for the full questionnaire, and the [ESS "variables and questions" Appendix](http://www.europeansocialsurvey.org/docs/round7/survey/ESS7_appendix_a7_e03_0.pdf) for a full list of variables and their names and possible values.

### Exercise 1.1

Check out the summary of `ess7_health`.

::: {.callout-caution collapse="true"}
#### Solution
```{r}
summary(ess7_health)
```
:::


## Criterion correlations

In this exercise, you will start by reproducing the "criterion correlations" for discussing your health with a general practiction (GP) from the slides. Then you will look at other variables in the dataset.

Note that the example code uses `dplyr` pipes, the `select` function, and friends. This is not mandatory but just easier to read. See <https://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html> if you'd like to find out more about using `dplyr`.

Possibly helpful: the [ESS "variables and questions" Appendix](http://www.europeansocialsurvey.org/docs/round7/survey/ESS7_appendix_a7_e03_0.pdf) for a full list of variables and their names and possible values.

### Exercise 1.2

 a. Correlate health discussion with the GP with the following variables: doing sports, sleeping problems, body-mass index, and age. Check this gives the same result as in the slides
 b. Look at more "criterion" variables: eating fruit and vegetables, happiness, education level, and being born in the country of residence
 c. Do the correlations you find agree with the expectations of the "nomological net" around "visiting the GP"? 


::: {.callout-tip collapse="true"}
#### I need a hint!
 - You can look at correlations with additional variables by adding these to the `select` statement
 - Remember R code is cAsE SENSITIVE and check for any typos (note most variable names here are in lower case)
 - If you need to know more about the variables, check out the Appendix linked above 
 - Check that the code provided to output only the correlations with GP, in alphabetical order, is used for both parts

A starting point for the code is below.

```{r, eval=FALSE}
# ess7_health is available in your workspace

# Correlate discussing health with GP with the following variables: 
#	doing sports, sleeping problems, body-mass index, and age
#   (the argument "pairwise.complete.obs" for the `cor` function 
#		deletes missing values for each pair of variables)

criterion_slides <- ess7_health %>% 
  dplyr::select(dshltgp, dosprt, <complete this>) %>% 
  cor(use = "pairwise.complete.obs")

# To make it easier to check your answer, 
#	sort by name and output only correlations with GP: 
criterion_slides <- 
  criterion_slides["dshltgp", sort(colnames(criterion_slides)[-1])] 
criterion_slides

# Now correlate with eating fruit and vegetables, happiness, 
#	education level, and being born in the country of residence
# And assign the result to criterion_extra

criterion_extra <- <complete this>
  
  
  # To make it easier to check your answer, 
  #	sort by name and output only correlations with GP: 
criterion_extra <- 
  criterion_extra["dshltgp", 
                  sort(colnames(criterion_extra)[-1])] 

criterion_extra
```
 
 
:::

::: {.callout-caution collapse="true"}
#### Solution

```{r}
# Correlate discussing health with GP with the following variables: doing sports, age, sleeping problems, and body-mass index
criterion_slides <- 
  ess7_health %>% 
  select(dshltgp, dosprt, agea, slprl, BMI) %>% 
  cor(use = "pairwise.complete.obs") 

criterion_slides <- 
  criterion_slides["dshltgp",
                   sort(colnames(criterion_slides)[-1])] 

criterion_slides
```

```{r}
# Correlate with eating fruit and vegetables, happiness, eduction level, and being born in the country of residence
criterion_extra <- 
  ess7_health %>%
  select(dshltgp, etfruit, eatveg, happy, eisced, brncntr) %>%
  cor(use = "pairwise.complete.obs")

criterion_extra <- 
  criterion_extra["dshltgp",
                  sort(colnames(criterion_extra)[-1])] 

criterion_extra
```
:::


### Exercise 1.3

Looking at the criterion correlations, one of them is close to zero. To which variable does this correlation correspond?
  
::: {.callout-caution collapse="true"}
#### Solution
Answer: "Born in country" has a correlation close to zero with GP visits. 

It is also not clear what we would have expected here. Maybe immigrants are unhealthier and need more treatment (negative association), or maye they are less able to find their way to the GP (positive association).
:::


### Exercise 1.4

What can we conclude from the fact that the criterion correlation with "born in country" is so small?

Choose one:  

    A. The validity of this question is low
    B. The reliability of this question is low
    C. The criterion variable has low validity 
    D. Nothing

::: {.callout-tip collapse="true"}
#### I need a hint!
Think back to the disadvantages of criterion validity from the slides.
:::

::: {.callout-caution collapse="true"}
#### Solution
The answer is D: nothing. It just doesn't really help to know this at all.
:::

## Internal consistency with factor analysis

As explained in the lectures, when there are no repeated measures of the same _question_, we can use repeated measures 
of the same _concept_ to get at the "internal consistency". 

This code uses the `cfa` function from the `lavaan` library, which is very flexible. The [model syntax](http://lavaan.ugent.be/tutorial/syntax1.html) is relatively easy to read: in this example, we only need to define which variables are regressed on the latent variable (concept) `health_latent`. This is done by using the `=~` operator, which means "is measured by".

Note that the results here may be different from those in the slides. 

If you would like to learn more on doing confirmatory factor analysis in R using `lavaan`, the tutorial at <http://lavaan.ugent.be/tutorial/cfa.html> is a good place to start. I can also recommend the book by Beaujean (see [here](http://lavaan.ugent.be/resources/books.html)) with accompanying R code.

### Exercise 1.5

a. Estimate the internal consistency coefficient of "discussing health with GP" based on the same three indicators as in the slides: GP, self-rated health, and sleeping problems.
b. Change the code to also use the number of reported health problems as an indicator 

::: {.callout-tip collapse="true"}
#### I need a hint!

Here is some sample code you can adapt to your needs. 

```{r, eval=FALSE}
library(lavaan)

# Use the cfa function from the lavaan package to fit a 
#	confirmatory factor analysis (CFA) model that gives the 
#	internal consistency  coefficients as "standardized loadings" (or "coefficients")  

# The latent concept "health_latent" is posited to be 
#		the common cause of these three variables ("indicators")
model <- "health_latent =~ dshltgp + health + slprl"

# Fit the model in lavaan and assign the result to a variable
fit <- cfa(model, data = ess7_health)

# Print the output of the CFA 
# 	standardized loadings will be the consistency coefficients 
summary(fit, standardized = TRUE)

# A different way of getting at these is:
consistencies <- standardizedSolution(fit) %>% filter(op == "=~")
consistencies

# Change the analysis so health_problems is also included as an indicator.

```
:::


::: {.callout-caution collapse="true"}
#### Solution

```{r}
# Use the cfa function from the lavaan package to fit a 
#	confirmatory factor analysis (CFA) model that gives the 
#	internal consistency  coefficients as "standardized loadings" (or "coefficients")  

# The latent concept "health_latent" is posited to be 
#		the common cause of these three variables ("indicators")
model <- "health_latent =~ dshltgp + health + slprl + health_problems"

# Fit the model in lavaan and assign the result to a variable
fit <- cfa(model, data = ess7_health)

# Print the output of the CFA 
# 	standardized loadings will be the consistency coefficients 
summary(fit, standardized = TRUE)

# A different way of getting at these is:
consistencies <- standardizedSolution(fit) %>% filter(op == "=~")
consistencies
```
:::


### Exercise 1.6

a. List the assumptions necessary to be able interpret the `Std.all` coefficients as the "internal consistency" of the items.
b. Why is one of the coefficients of an opposite sign to the others?
c. Assuming the assumptions all hold, which item is the best measure of the underlying latent construct?

::: {.callout-caution collapse="true"}
#### Solution

a. The assumptions are:
  - No correlated error
  - True scores all measure same construct
  - No differential error
b. Because three of the indicators indicate _bad_ health, while one (`health`) indicates _good_ health.
c. The indicator `health`. The indicator `health_problems` is very close in quality as an indicator of the LV.

:::

### Exercise 1.7

After an additional indicator was used to measure the latent concept "health_latent", the internal consistency  estimate for "GP" changed. What could be the explanation?

    A. Sampling fluctuations
    B. Violation of assumptions
    C. Both sampling and assumption violations
    D. None of the above
    
::: {.callout-caution collapse="true"}
#### Solution

If the model is true (so no assumptions are violated) and there is infinite data, using more indicators will not change the consistency estimate. So either sampling or assumption violations can cause this change (Answer C).
:::


## Multitrait-multimethod models

The correlations between the variables measured in the multitrait-multimethod (MTMM) experiment from the slides from Saris & Gallhofer are plotted below (the matrix itself will be called `R` here). 

The "correlation plot" below shows these as larger or smaller circles. The larger the circle, the stronger the correlation (positive or negative).

```{r, echo=FALSE}
cors <- 
  "1000
 481  1000
 373  552  1000
-626 -422 -410  1000
-429 -663 -532  642  1000
-453 -495 -669  612  693  1000
-502 -347 -332  548  436  438  1000
-370 -608 -399  429  653  466  556  1000
-336 -406 -566  406  471  638  514  558  1000"

library(lavaan)
R <- lavaan::getCov(cors)/1000

colnames(R) <- rownames(R) <-
  paste0(paste0("T", rep(1:3, 3)),
         paste0("M", rep(1:3, each=3)))

corrplot::corrplot(R)         
```

::: {.callout-note collapse="true"}
#### Click here to show correlations in a table

```{r, echo=FALSE}
R %>% knitr::kable()
```
:::

The variables have been renamed to show which "trait" (survey question) and "method" (way of asking the question) they correspond to. For example, T1M1 might refer to "satisfaction with the economy" (T1) measured on a four point scale (M1), and T1M2 to "satisfaction with the economy" (T1) measured on an eleven point scale (M2).

### Exercise 1.8

Which correlations from the MTMM experiment are strongest?
    
    A. Those between different questions measured in the same way ("heterotrait-monomethod")
    B. Those between the same questions measured in different ways ("monotrait-heteromethod")
    C. Those between different questions measured in different ways ("heteromethod-heterotrait")
    D. All the correlations are the same



::: {.callout-tip collapse="true"}
#### I need a hint!

Try to find the different groups of correlations mentioned in the picture. Which group has the largest circles overall? 
:::

::: {.callout-caution collapse="true"}
#### Solution

Answer: B. Those between the same questions measured in different ways ("monotrait-heteromethod")

This seems like a good thing. This classification of groups of correlations is due to Campbell and Fiske (1959), who based their assessment of the measurement properties purely on the type of consideration you have just done.
:::

### Exercise 1.9

MTMM _models_ can be applied to MTMM _data_ to obtain estimates of the reliability coefficients and method effects. 

Since the MTMM _design_ crosses "traits" (survey questions in our case) with "methods" (ways of asking those questions), this is a matter of specifying the right indicator for each factor in a factor analysis.

This time, due to the study design, the interpretation of the standardized factor loadings is that they represent "reliability coefficients" and "method effects" of the questions studied. 


a. Formulate the MTMM model for the correlations in the MTMM correlation matrix `R` by replacing the `...` dots in the code below;
b. Run the model to obtain estimates using the ready-made code;
c. Interpret the results by looking at the standardized estimates. 

_HINT_: The standardized coefficients on the T* factors are the reliability coefficient estimates;
 The standardized coefficients on the M* factors are the method effect estimates.

#### Ready-made code for MTMM model

Adjust the code below to answer the questions above.

```{r, eval=FALSE}
library(lavaan)
library(dplyr)

# Show the correlation matrix:
R

# Define the MTMM model below (see slides)
model <- "
  # Fill in the measurement of the traits and methods.
  # Note that the names are T1M1, T1M2, etc.

  # Model for the methods: prefix every variable with 1*, 
  #			e.g use M1 =~ 1*T1M1 + ...
  M1 =~ ...    						# Replace the dots 
  M2 =~ ...
  M3 =~ ...

  # Model for the traits: don't prefix indicators with anything
  T1 =~ ...
  T2 =~ ...
  T3 =~ ...

  # This specifies that the traits correlate. You can leave it as-is
  T1 ~~ T2 + T3
  T2 ~~ T3

  # This identifies the latent trait variables by 
  #		standardizing them to variance 1. You can leave it as-is.
  T1 ~~ 1*T1
  T2 ~~ 1*T2
  T3 ~~ 1*T3
"

# Fit the model as a CFA using lavaan
fit <- lavaan(model, sample.cov = R, 
              sample.nobs = 424, 
              auto.cov.lv.x = FALSE, 
              auto.fix.first = FALSE, auto.var = TRUE)

# Summarize the results
summary(fit, standardize = TRUE)

# The standardized loadings (those with op "=~") are 
#		the reliability coefficients (for Tx) 
#   	and method effects (for Mx):
std_estimates <- standardizedSolution(fit) %>% dplyr::filter(op == "=~") %>% dplyr::arrange(lhs, rhs)
std_estimates
```

::: {.callout-tip collapse="true"}
#### I need a hint!

- Use the names of the variables: "T1M1" belongs to trait factor T1 and method factor M1, for instance
- Make sure the method indicators each have their loading set to 1 by using the 1* suggested
- Make sure the original code for the model is not accidentally removed: only change the dots.
:::

::: {.callout-caution collapse="true"}
#### Solution

```{r}
# Show the correlation matrix:
R

# Define the MTMM model below (see slides)
model <- "
M1 =~ 1*T1M1 + 1*T2M1 + 1*T3M1
M2 =~ 1*T1M2 + 1*T2M2 + 1*T3M2
M3 =~ 1*T1M3 + 1*T2M3 + 1*T3M3

T1 =~ T1M1 + T1M2 + T1M3
T2 =~ T2M1 + T2M2 + T2M3
T3 =~ T3M1 + T3M2 + T3M3

T1 ~~ T2 + T3
T2 ~~ T3

T1 ~~ 1*T1
T2 ~~ 1*T2
T3 ~~ 1*T3"

# Fit the model as a CFA using lavaan
fit <- lavaan(model, sample.cov = R, 
              sample.nobs = 424, 
              auto.cov.lv.x = FALSE, 
              auto.fix.first = FALSE, auto.var = TRUE)

# Summarize the results
summary(fit, standardize = TRUE)

# The standardized loadings are the reliability coefficients (for Tx) 
#   	and method effects (for Mx):
std_estimates <- standardizedSolution(fit) %>% dplyr::filter(op == "=~") %>% dplyr::arrange(lhs, rhs)
std_estimates
```
:::

If you managed to get this, excellent job! MTMM modeling can be quite confusing, especially at the beginning. With practice it will become more natural, and can be a powerful tool in your measurement error arsenal. 

## Quasi-simplex model

These models can be used to estimate the measurement error variance in longitudinal data. Such data are available from the [LISS panel](https://www.lissdata.nl/lissdata/about-panel). 

In the slides, error estimation in "internet use" using three timepoints (years 2008-2010) is explained. In the dataset, which is included in the `lavaan.survey` package as `liss`, a fourth timepoint, 2011, is also available (`cs11d247`). Adjust the model to the right to include `cs11d247` so it also estimates the reliability in 2011.

The full study documentation as well as the raw data are publicly available at <http://www.lissdata.nl/dataarchive/study_units/view/6>. (BTW: LISS is an awesome publicly available longitudinal data source you should definitely check out if you're ever looking for high-quality social science data)

For now, we will load a prepared dataset from LISS stored on my website.

```{r}
load(url("http://daob.nl/files/SURV730/liss.rdata"))
```

Since it is likely that you have not encountered `lavaan`, SEM, or quasi-simplex modeling before, some ready-made code for such a model applied to the LISS data is provided below.


#### Ready-made R code for quasi-simplex model

```{r, eval=FALSE}
# Formulate the quasi-simplex model for three timepoints
# Adapt this to also include the measurement at 2011, cs11d247
model.qs <- "
  # The part where each true score variable at time t 
  #    is measured by the survey answers at time t:
  cs08 =~ 1 * cs08a247
  cs09 =~ 1 * cs09b247
  cs10 =~ 1 * cs10c247

  # The part where the true score at time t 
  #	    is regressed on the true score at time t-1:
  # a.k.a. the 'AR(1) process':
  cs09 ~ cs08
  cs10 ~ cs09

  # The part where the measurement error variance is 
  #		assumed equal over time:
  cs08a247 ~~ vare * cs08a247
  cs09b247 ~~ vare * cs09b247
  cs10c247 ~~ vare * cs10c247
"
# Fit the quasi-simplex model with lavaan as a SEM:
fit.liss <- lavaan(model.qs, auto.var = TRUE, data = liss)

# Output the estimates, including reliability coefficients and stability across time:
summary(fit.liss, standardized = TRUE)

# This is to check the solution:
std_estimates <- fit.liss %>% 
  standardizedSolution %>% 
  filter(op == "=~") %>% 
  arrange(lhs, rhs)

std_estimates
```


### Exercise 1.10

Instructions: 
- Change the quasi-simplex model for 2008-2010 to also include 2011
- Do this by adding one additional line of code for each of the three parts of the model 
- Note that the newly used observed variable name is `cs11d247` (so with a d)

a. Which assumptions do we need to make in order for the estimates to reflect the reliability of this survey question?
b. What is the estimated reliability of this survey question according to the quasi-simplex model?
c. What is the estimated stability over time of this survey question according to the quasi-simplex model?

::: {.callout-caution collapse="true"}
#### Solution

```{r}
model.qs <- "
  cs08 =~ 1 * cs08a247
  cs09 =~ 1 * cs09b247
  cs10 =~ 1 * cs10c247
  cs11 =~ 1 * cs11d247

  cs09 ~ cs08
  cs10 ~ cs09
  cs11 ~ cs10

  cs08a247 ~~ vare * cs08a247
  cs09b247 ~~ vare * cs09b247
  cs10c247 ~~ vare * cs10c247
  cs11d247 ~~ vare * cs11d247

"

fit.liss <- lavaan(model.qs, auto.var = TRUE, data = liss)

summary(fit.liss, standardized = TRUE)

# This is to check the solution
std_estimates <- fit.liss %>% 
  standardizedSolution %>% 
  filter(op == "=~") %>% 
  arrange(lhs, rhs)

std_estimates
```

a. From the slides, we have the following assumptions:
- No
correlated
error
- Identical
error
variances over
time
- No
differential
error
- True
score
change
AR(1)
- All
time-specific
variance
is
measurement
error

Looking at the standardized estimates from the results above, we find that:

b. The reliability of this item estimated by the quasi-simplex model is about `r round(std_estimates$est.std[1], 1)`. 

c. The stability of this item over time is about `r round(standardizedSolution(fit.liss) %>% filter(op == "~") %>% select("est.std") %>% unlist() %>% median(), 1)`. 
 
:::


